{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "If a datapoint is incorrectly predicted by the first model (and then probably all the rest of the models) will combining the predictions produce better results? Probably not. That's where boosting comes in.\n",
    "\n",
    "Boosting is a sequential process, where each subsequent model attempts to correct the errors of the previous model. The succeeding models are dependent on the previous model.\n",
    "\n",
    "Here's a visualization of the steps:\n",
    "\n",
    "1. A subset is created from the original dataset.\n",
    "\n",
    "2. Initially, all data points are given equal weights.\n",
    "\n",
    "3. A base model is created on this subset.\n",
    "\n",
    "4. This model is used to make predictions on the whole dataset\n",
    "![4](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2015/11/dd2-e1526989487878.png)\n",
    "\n",
    "5. Errors are calculated using the actual values and predicted values\n",
    "\n",
    "6. Observations which are incorrectly predicted are given higher weights (The misclassified blue points above)\n",
    "\n",
    "7. Another model is created and predictions are made on the dataset (this model tried to correct errors from the previous model)\n",
    "![7](https://www.analyticsvidhya.com/wp-content/uploads/2015/11/boosting10.png)\n",
    "\n",
    "8. Multiple models are created, each correcting the errors of the previous model.\n",
    "\n",
    "9. The final model (strong learned) is the weighted mean of all the models (weak learners)\n",
    "![9](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2015/11/dd4-e1526551014644.png)\n",
    "\n",
    "Thus, the boosting algorithm combines a number of weak learners to form a strong learner.\n",
    "![final](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2015/11/dd4-e1526551014644.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Implementations\n",
    "* AdaBoost\n",
    "* Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "AdaBoost (Adaptive Boosting), is perhaps the first successful boosting ensemble algorithm - it generally works by weighting instances in the dataset by how easy or difficult they are to classify, allowing the algorithm to pay more or less attention to them in the construction of subsequent models.\n",
    "\n",
    "We'll implement one using sklearn's `AdaBoostClassifier` with 30 decision trees on the \"pima indians\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jfields\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:205: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import packages and data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "URL = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'\n",
    "features = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "df = pd.read_csv(URL, names=features)\n",
    "\n",
    "X = df.iloc[:, 0:8]\n",
    "y = df.iloc[:, 8]\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate and train the model\n",
    "num_trees = 30\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=num_trees, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.760457963089542\n"
     ]
    }
   ],
   "source": [
    "# Get results\n",
    "results = cross_val_score(abc, X, y, cv=kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Boosting\n",
    "Stochastic Gradient Boosting or Gradient Boosting Machines (GBM) are one of the most sophisticated ensemble techniques - one that also provides really good performance.\n",
    "\n",
    "It works like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Married</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Current City</th>\n",
       "      <th>Monthly Income</th>\n",
       "      <th>Age (target)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>51000</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>25000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>74000</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>29000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>37000</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Married Gender Current City  Monthly Income  Age (target)\n",
       "0   1       Y      M            A           51000            35\n",
       "1   2       N      F            B           25000            24\n",
       "2   3       Y      M            A           74000            38\n",
       "3   4       N      F            A           29000            30\n",
       "4   5       N      F            B           37000            33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Data\n",
    "df = pd.DataFrame(data=[[1, 'Y', 'M', 'A', 51000, 35], [2, 'N', 'F', 'B', 25000, 24], [3, 'Y', 'M', 'A', 74000, 38],\n",
    "                       [4, 'N', 'F', 'A', 29000, 30], [5, 'N', 'F', 'B', 37000, 33]],\n",
    "                  columns=['ID', 'Married', 'Gender', 'Current City', 'Monthly Income', 'Age (target)'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict `Age`\n",
    "1. The mean age is assumed to be the predicted value for all observations in the dataset\n",
    "2. The errors are calculated using this mean prediction and actual values of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Married</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Current City</th>\n",
       "      <th>Monthly Income</th>\n",
       "      <th>Age (target)</th>\n",
       "      <th>Mean Age (prediction 1)</th>\n",
       "      <th>Residual 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>51000</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>25000</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>74000</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>29000</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>37000</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Married Gender Current City  Monthly Income  Age (target)  \\\n",
       "0   1       Y      M            A           51000            35   \n",
       "1   2       N      F            B           25000            24   \n",
       "2   3       Y      M            A           74000            38   \n",
       "3   4       N      F            A           29000            30   \n",
       "4   5       N      F            B           37000            33   \n",
       "\n",
       "   Mean Age (prediction 1)  Residual 1  \n",
       "0                       32           3  \n",
       "1                       32          -8  \n",
       "2                       32           6  \n",
       "3                       32          -2  \n",
       "4                       32           1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Mean Age (prediction 1)'] = [32,32,32,32,32]\n",
    "df['Residual 1'] = [3, -8, 6, -2, 1]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. A tree model is created using the errors calculated above as the target variable. Our objective is to find the best split to minimize the error\n",
    "4. The predictions by this model are combined with prediction 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Married</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Current City</th>\n",
       "      <th>Monthly Income</th>\n",
       "      <th>Age (target)</th>\n",
       "      <th>Mean Age (prediction 1)</th>\n",
       "      <th>Residual 1</th>\n",
       "      <th>Prediction 2</th>\n",
       "      <th>Combine (mean+pred2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>51000</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>25000</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>-8</td>\n",
       "      <td>-5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>74000</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>29000</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>-2</td>\n",
       "      <td>-5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>37000</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Married Gender Current City  Monthly Income  Age (target)  \\\n",
       "0   1       Y      M            A           51000            35   \n",
       "1   2       N      F            B           25000            24   \n",
       "2   3       Y      M            A           74000            38   \n",
       "3   4       N      F            A           29000            30   \n",
       "4   5       N      F            B           37000            33   \n",
       "\n",
       "   Mean Age (prediction 1)  Residual 1  Prediction 2  Combine (mean+pred2)  \n",
       "0                       32           3             3                    35  \n",
       "1                       32          -8            -5                    27  \n",
       "2                       32           6             3                    35  \n",
       "3                       32          -2            -5                    27  \n",
       "4                       32           1             3                    35  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename({'Residual 1': 'Residual 1 (new target)'})\n",
    "df['Prediction 2'] = [3, -5, 3, -5, 3]\n",
    "df['Combine (mean+pred2)'] = [35, 27, 35, 27, 35]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The value calculated above is the new prediction\n",
    "6. New errors are calculated using this predicted value and the actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Married</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Current City</th>\n",
       "      <th>Monthly Income</th>\n",
       "      <th>Age (target)</th>\n",
       "      <th>Mean Age (prediction 1)</th>\n",
       "      <th>Residual 1</th>\n",
       "      <th>Prediction 2</th>\n",
       "      <th>Combine (mean+pred2)</th>\n",
       "      <th>Residual 2 (latest target)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>51000</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>25000</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>-8</td>\n",
       "      <td>-5</td>\n",
       "      <td>27</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>74000</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>29000</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>-2</td>\n",
       "      <td>-5</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>37000</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Married Gender Current City  Monthly Income  Age (target)  \\\n",
       "0   1       Y      M            A           51000            35   \n",
       "1   2       N      F            B           25000            24   \n",
       "2   3       Y      M            A           74000            38   \n",
       "3   4       N      F            A           29000            30   \n",
       "4   5       N      F            B           37000            33   \n",
       "\n",
       "   Mean Age (prediction 1)  Residual 1  Prediction 2  Combine (mean+pred2)  \\\n",
       "0                       32           3             3                    35   \n",
       "1                       32          -8            -5                    27   \n",
       "2                       32           6             3                    35   \n",
       "3                       32          -2            -5                    27   \n",
       "4                       32           1             3                    35   \n",
       "\n",
       "   Residual 2 (latest target)  \n",
       "0                           0  \n",
       "1                          -3  \n",
       "2                          -3  \n",
       "3                           3  \n",
       "4                          -2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Residual 2 (latest target)'] = [0, -3, -3, 3, -2]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps 2-6 are repeated until the maximum number of iterations is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll implement using sklearn's `GradientBoostingClassifier` with the same dataset above and 100 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate the model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "num_trees = 100\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=num_trees, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7642857142857143\n"
     ]
    }
   ],
   "source": [
    "# get results\n",
    "results = cross_val_score(gbc, X, y, cv=kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "XGBoost (Extreme Gradient Boosting) is an advanced implementation of the gradient boosting algorithm. It's highly effective, has great predictive power, and is much faster than other gradient boosting techniques. It also includes a variety of regularization techniques which reduces overfitting and improves overall performance.\n",
    "\n",
    "Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "URL = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "\n",
    "features = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "data = pd.read_csv(URL, names=features)\n",
    "\n",
    "X = data.iloc[:, 0:8]\n",
    "y = data.iloc[:, 8]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate and train the model\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  74.02%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100.0: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM\n",
    "Light GBM beats most algorithms when the dataset is extremely large.\n",
    "\n",
    "It's a gradient boosting framework that uses tree-based algorithms and follows a leaf-wise approach while others work in a level-wise approach. Like this:\n",
    "![level](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/11194110/leaf.png)\n",
    "![leaf](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/11194227/depth.png)\n",
    "\n",
    "A leaf-wise approach may cause over-fitting on smaller datasets but this can be avoided by using the `max_depth` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "Handling categorical variables is a tedious process, especially when you have a large number of such variables. When your categorical variables have too many labels, performing one hot encoding on them exponentially increases the dimensionality and it becomes really difficult to work with the dataset. \n",
    "\n",
    "CatBoost can automatically deal with categorical variables and does not require extensive data preprocessing like other machine learning algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
