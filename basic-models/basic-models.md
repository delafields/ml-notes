# Basic Models

Notes on classical machine learning techniques and algorithms.

##### Linear Regression
* Linear Regression [ [Notebook](Linear-Regression.ipynb) ]
* Ridge & Lasso Regression [ [Notebook](Ridge-Lasso-Regression.ipynb) ]
* Evaluation Metrics [ [Notebook](Regression-Evaluation-Metrics.ipynb) ]

##### Logistic Regression
* Logistic Regression [ [Notebook](Logistic-Regression.ipynb) ]
* Cross Entropy Loss [ [Notebook](Cross-Entropy-Loss.ipynb) ]
* Evaluation Metrics [ [Notebook](Classification-Evaluation-Metrics.ipynb) ]

##### SVMs
* SVMs [ [Notebook](SVM.ipynb) ]

##### Clustering
* K-Means [ [Notebook](K-Means.ipynb) ]
* K Nearest Neighbors [ [Notebook](K-Nearest-Neighbors.ipynb) ]

##### Bayesian
* Naive Bayes [ [Notebook](Naive-Bayes.ipynb) ]

##### Trees
* Random Forests [ [Notebook](Random-Forests.ipynb) ]

##### Ensemble Methods
* Boosting [ [Notebook](Ensemble-Methods/Boosting.ipynb) ]
* Bagging [ [Notebook](Ensemble-Methods/Bagging.ipynb) ]
* Stacking & Blending [ [Notebook](Ensemble-Methods/Stacking-and-Blending.ipynb) ]
* Max Voting, Averaging, and Weighted Averaging [ [Notebook](Ensemble-Methods/MaxVoting-Averaging-WeightedAveraging.ipynb) ]

##### Cross Validation
* CV Techniques [ [Notebook](Cross-Validation-Techniques.ipynb) ]

##### Feature Engineering
* One Hot Encoding [ [Notebook](One-Hot-Encoding.ipynb) ]

*Note - When taking these notes I did not attribute the authors of most of this stuff. Going forward, they will be attributed.*